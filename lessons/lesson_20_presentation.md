---
marp: true
paginate: false

style: |
  table {
    font-size: 0.7em;
  }
  section {
    font-size: 3em;
  }
  section.centered {
    display: flex;
    flex-direction: column;
    justify-content: center;
    text-align: center;
  }
  .two-columns {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 40px;
    align-items: center;
  }
---
<!-- _class: centered -->
# K-Nearest Neighbors (K-NN)
## Классификация на основе соседей

---
# K-NN

**K-Nearest Neighbors** - один из самых простых и интуитивных алгоритмов машинного обучения

**Основная идея:**
Объект классифицируется на основе **ближайших к нему соседей**

---
# Как работает K-NN?

**Шаг 1:** Выбираем количество соседей **K** (например, K=3)

**Шаг 2:** Для нового объекта находим **K ближайших** соседей

**Шаг 3:** Смотрим на **классы** этих соседей

**Шаг 4:** **Голосование:** класс, который встречается чаще всего

---
# Пример
![w:900](/images/k_nn_example.png)

---
# Метрика расстояния

**Евклидово расстояние** (самое популярное):

$$d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$

**Для многих признаков:**

$$d = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}$$

---
# Выбор K: очень важно!

<div class="two-columns">

<div>

**K = 1** (слишком мало)
- Очень чувствителен к шуму
- Переобучение
- Нестабильные предсказания

</div>

<div>

**K = 100** (слишком много)
- Учитывает далёкие объекты
- Недообучение
- Игнорирует локальные паттерны

</div>

</div>

**Оптимальный K:** обычно 3, 5, 7 (нечётные числа)

---
# Преимущества K-NN

**Очень простой** для понимания

**Не требует обучения** (lazy learning)

**Работает с любыми данными** (нелинейные границы)

**Многоклассовая классификация**

---
# Недостатки K-NN

**Медленное предсказание** (нужно считать все расстояния)

**Требует много памяти** (хранит все данные)

**Чувствителен к масштабу** (нужна нормализация!)

**Плохо работает с большим числом признаков** (curse of dimensionality)

---
# Важно: Масштабирование!

**Без масштабирования:**
- Возраст: 25 лет
- Зарплата: 500,000 ₸

Расстояние будет определяться **только зарплатой**

**С масштабированием (StandardScaler):**
- Возраст: 0.5
- Зарплата: 0.3
---
# Когда использовать K-NN?

**Небольшие датасеты** (до 10,000 строк)

**Мало признаков** 

**Нелинейные границы** между классами

**Нужна простота** и интерпретируемость

Избегать для **больших данных**

---
**1. Рекомендательные системы**
- Поиск похожих товаров
- Поиск похожих пользователей

**2. Распознавание образов**
- Рукописные цифры
- Классификация изображений

**3. Медицина**
- Диагностика на основе симптомов

---
# Ключевые выводы

1) K-NN классифицирует по **большинству голосов** соседей

2) **K** - главный гиперпараметр (обычно 3, 5, 7)

3) **Обязательно** масштабировать данные!

4) Простой, но **медленный** на больших данных

5) Не строит модель - просто **запоминает** данные
