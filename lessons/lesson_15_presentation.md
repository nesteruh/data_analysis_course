---
marp: true
paginate: false

style: |
  table {
    font-size: 0.7em;
  }
  section {
    font-size: 3em;
  }
  section.centered {
    display: flex;
    flex-direction: column;
    justify-content: center;
    text-align: center;
  }
  .two-columns {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 40px;
    align-items: center;
  }
---
<!-- _class: centered -->
# Логистическая регрессия

---
# Что мы умеем? (Уроки 11-14)

**Линейная регрессия** - предсказание непрерывных значений:
- Продолжительность жизни: 72.5 года
- Зарплата: $85,000
- Цена дома: $450,000 
**Формула:**
$$y = w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + ... + w_n \cdot x_n$$

Выход: **любое число** от -∞ до +∞

---
# Новая задача: Классификация

Часто нужно предсказывать **категории**, а не числа:
- Болен пациент или здоров? -> **0** или **1**
- Спам это или нет? -> **0** или **1**
- Клиент уйдет или останется? -> **0** или **1**
- Транзакция - мошенничество? -> **0** или **1**

**Бинарная классификация**: только 2 класса (0 и 1)

---
# Проблема линейной регрессии


| Возраст | Холестерин | Болезнь сердца |
|---------|------------|----------------|
| 45      | 200        | 0 (здоров)     |
| 62      | 280        | 1 (болен)      |
| ?       | ?          | **0.73**      |
 
 Нельзя интерпретировать как вероятность

---
# Логистическая регрессия

Превратить любое число в диапазон [0, 1] 

$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

Где $z = w_0 + w_1 \cdot x_1 + w_2 \cdot x_2 + ... + w_n \cdot x_n$
**Свойства sigmoid:**
- Принимает любое число
- Возвращает значение между 0 и 1
- Можно интерпретировать как **вероятность**

---
# Sigmoid функция: Визуализация
<div class="two-columns">
<div>

![w:1000](../images/sigmoid_function.example.png)

</div>
<div>
- σ(-5) = 0.007 ≈ 0% вероятность класса 1
- σ(0) = 0.5 -> 50%
- σ(5) = 0.993 ≈ 100%
</div>
</div>

---
# Интерпретация результата

**Выход модели** -> вероятность принадлежности к классу 1

| Вероятность | Интерпретация            | Предсказание |
|-------------|--------------------------|--------------|
| 0.05        | 5% вероятность болезни   | **0** (здоров) |
| 0.35        | 35% вероятность          | **0**          |
| 0.50        | 50% (граница)            | **0** или **1** |
| 0.75        | 75% вероятность болезни  | **1** (болен)  |
| 0.95        | 95% вероятность          | **1**          |

**Порог (threshold)**: можно установить

---
# Предсказание болезни сердца

**Задача:** По медицинским данным пациента предсказать риск болезни
**Признаки:**
- Возраст 
- Тип боли в груди 
- Максимальный пульс

**Целевая переменная:** 0 = здоров, 1 = болен

---
# Новые метрики

**Для регрессии**: R², MAE, RMSE

**Для классификации**:
- **Accuracy** - общая точность
- **Precision** - точность позитивных предсказаний
- **Recall** - полнота (сколько нашли из всех больных)
- **F1-Score** - гармоническое среднее
- **ROC-AUC** - площадь под ROC кривой

---
# Confusion Matrix (Матрица ошибок)

|                  | Предсказано: 0 | Предсказано: 1 |
|------------------|----------------|----------------|
| **Реально: 0**   | TN (True Negative)<br>Правильно: здоров | FP (False Positive)<br>Ошибка I рода |
| **Реально: 1**   | FN (False Negative)<br>Ошибка II рода | TP (True Positive)<br>Правильно: болен |

- **TP**: сказали болен, реально болен 
- **TN**: сказали здоров, реально здоров 
- **FP**: сказали болен, реально здоров  
- **FN**: сказали здоров, реально болен 

---
$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$
Общая точность: сколько смогли предсказать
$$\text{Precision} = \frac{TP}{TP + FP}$$
Из тех, кого назвали больными, сколько реально больны
$$\text{Recall} = \frac{TP}{TP + FN}$$
Из всех реально больных, сколько мы нашли

---
# Какая метрика важнее?

**Медицина (рак, болезни сердца):**
- **Recall** важнее, лучше лишний раз проверить, чем пропустить болезнь
- FN (пропустили больного) - критично 

**Спам-фильтр:**
- **Precision** важнее, не хотим терять важные письма
- FP (важное письмо в спам) - критично 


---
# Threshold (порог решения)

**По умолчанию**: если вероятность > 0.5, то класс 1

**Можно менять порог:**

| Threshold | Эффект                           |
|-----------|----------------------------------|
| 0.3       | Больше предсказываем 1 -> ↑ Recall, ↓ Precision |
| 0.5       | Стандартный баланс               |
| 0.7       | Реже предсказываем 1 -> ↓ Recall, ↑ Precision |

**ROC кривая** показывает качество модели при **всех порогах**

---
# Градиентный спуск 

**В линейной регрессии:**
- Loss function: MSE (Mean Squared Error)
- $MSE = \frac{1}{n}\sum(y - \hat{y})^2$

**В логистической регрессии:**
- Loss function: **Log Loss** (Binary Cross-Entropy)
- $LogLoss = -\frac{1}{n}\sum[y \log(\hat{y}) + (1-y)\log(1-\hat{y})]$

**Градиентный спуск** работает так же, но как другая функция

---
# Ключевые отличия от регрессии

| Аспект             | Линейная регрессия      | Логистическая регрессия |
|--------------------|-------------------------|-------------------------|
| **Задача**         | Предсказание чисел      | Предсказание категорий  |
| **Выход**          | -∞ до +∞                | 0 до 1 (вероятность)    |
| **Функция**        | Линейная                | Sigmoid                 |
| **Loss**           | MSE                     | Log Loss                |
| **Метрики**        | R², MAE, RMSE           | Accuracy, Precision, Recall, AUC |
| **Интерпретация**  | Числовое значение       | Вероятность класса      |